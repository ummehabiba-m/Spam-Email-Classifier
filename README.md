ğŸ“§ Spam Email Classifier

A machine learning project to detect spam emails using Python, Scikit-learn, and Flask. This project automatically classifies emails as Spam or Ham to help users manage their inbox efficiently and securely.

ğŸš€ Project Motivation

Emails are an essential communication tool, but spam and unsolicited emails create several problems:

Waste time and reduce productivity

Increase risk of phishing and scams

Overload inboxes, making it hard to identify important emails

Goal: Build a solution that automatically identifies spam emails, helping users focus on important messages while minimizing risks.

ğŸ¯ Problem Statement

Manually checking hundreds of emails every day is inefficient and error-prone. Traditional filters might not detect all spam types.

Solution:

Train a machine learning model to classify emails accurately

Provide a simple web interface for real-time predictions

ğŸ“‚ Dataset

Source: Kaggle Spam Emails

Columns:

text â†’ full email content

spam â†’ 1 = spam, 0 = ham

ğŸ›  Methods & Implementation
1. Preprocessing

Lowercasing text

Removing punctuation, numbers, and HTML tags

Removing stopwords

Stemming words to their root form

Reason: Reduces noise and keeps only meaningful words for classification.

2. Feature Extraction

Method: TF-IDF Vectorization

Converts text to numerical features

Highlights important words that are frequent in one email but rare in all emails

Reason: Captures patterns that distinguish spam from ham without overemphasizing common words.

3. Machine Learning Models

Naive Bayes (MultinomialNB)

Fast, interpretable, excellent for short spam messages

Logistic Regression

Models probability of spam

Handles large feature sets and subtle patterns

Effectiveness: Both models are widely used in text classification and show high accuracy for spam detection.

4. Web Interface

Built using Flask

Users can paste email content and instantly get a Spam/Ham prediction

ğŸ“ˆ Project Workflow

Load Dataset â†’ Read emails from CSV

Preprocess Text â†’ Clean and stem words

Vectorize Text â†’ Convert to TF-IDF features

Train Models â†’ Naive Bayes & Logistic Regression

Evaluate â†’ Precision, Recall, F1-score

Save Models â†’ model.pkl & vectorizer.pkl

Web App â†’ Real-time email classification using Flask

ğŸ’¡ Key Outcomes / Delivery Report

Why we built it: Automate spam detection, improve inbox management, and reduce security risks.

How it solves the problem: Uses ML to identify spam patterns and classify emails automatically.

Methods used: Preprocessing, TF-IDF vectorization, Naive Bayes, Logistic Regression, Flask.

Why these methods: Proven efficiency in text classification; lightweight and interpretable.

Effectiveness: Can detect classic spam emails with high accuracy; professional or legitimate emails are correctly classified as Ham.

Future improvements:

Detect promotional emails separately

Use deep learning for higher accuracy

Multi-class classification (ham, spam, promotion, phishing)

ğŸ“‚ Folder Structure
spam-email-classifier/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emails.csv            # Kaggle dataset
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py         # text cleaning functions
â”‚   â”œâ”€â”€ train.py              # train ML models
â”‚   â””â”€â”€ predict.py            # predict new emails
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Flask web interface
â”œâ”€â”€ app.py                    # Flask app
â”œâ”€â”€ model.pkl                 # trained Naive Bayes model
â”œâ”€â”€ vectorizer.pkl            # TF-IDF vectorizer
â”œâ”€â”€ requirements.txt          # project dependencies
â””â”€â”€ README.md                 # this file

âš¡ Installation

Clone repository:

git clone https://github.com/ummehabiba-m/Spam-Email-Classifier.git
cd Spam-Email-Classifier


Install dependencies:

pip install -r requirements.txt

â–¶ï¸ Usage
Train the Model
python src/train.py

Test Prediction
python src/predict.py

Run Web App
python app.py


Open browser: http://127.0.0.1:5000/

Paste an email â†’ click Check â†’ see Spam/Ham

ğŸ“Š Evaluation Metrics

Precision, Recall, F1-score

Both models achieve high accuracy on the Kaggle dataset

Naive Bayes is faster, Logistic Regression handles complex patterns

ğŸ“Œ License

MIT License
